{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c709dacc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import pytz\n",
    "from datetime import datetime\n",
    "import tensorflow as tf\n",
    "\n",
    "MODEL_DIR = \"saved_model\"\n",
    "MODEL_PATH = os.path.join(MODEL_DIR, \"sign_mlp.h5\")\n",
    "LABELS_PATH = os.path.join(MODEL_DIR, \"labels.json\")\n",
    "\n",
    "st.set_page_config(layout=\"wide\", page_title=\"Sign Language Detector\")\n",
    "\n",
    "def in_allowed_time():\n",
    "    tz = pytz.timezone(\"Asia/Kolkata\")\n",
    "    now = datetime.now(tz)\n",
    "    hour = now.hour\n",
    "    return 18 <= hour < 22, now.strftime(\"%Y-%m-%d %H:%M:%S %Z\")\n",
    "\n",
    "@st.cache_resource\n",
    "def load_model_and_labels():\n",
    "    if not os.path.exists(MODEL_PATH) or not os.path.exists(LABELS_PATH):\n",
    "        return None, None\n",
    "    model = tf.keras.models.load_model(MODEL_PATH)\n",
    "    with open(LABELS_PATH, \"r\") as f:\n",
    "        labels = json.load(f)\n",
    "    return model, labels\n",
    "\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "def extract_landmarks_from_image(image_bgr):\n",
    "    image = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)\n",
    "    with mp_hands.Hands(static_image_mode=True, max_num_hands=1,\n",
    "                        min_detection_confidence=0.5) as hands:\n",
    "        res = hands.process(image)\n",
    "        if res.multi_hand_landmarks:\n",
    "            lm = res.multi_hand_landmarks[0]\n",
    "            vec = np.array([[p.x, p.y, p.z] for p in lm.landmark]).flatten()\n",
    "            return vec, lm\n",
    "    return None, None\n",
    "\n",
    "def predict_from_vector(model, labels, vec):\n",
    "    proba = model.predict(vec.reshape(1, -1))[0]\n",
    "    idx = int(np.argmax(proba))\n",
    "    return labels[idx], float(proba[idx]), proba\n",
    "\n",
    "model, labels = load_model_and_labels()\n",
    "\n",
    "st.title(\"Sign Language Detection — Upload Image & Real-time (Operational 18:00–22:00 IST)\")\n",
    "allowed, ts = in_allowed_time()\n",
    "st.write(f\"Current time (Asia/Kolkata): {ts}\")\n",
    "if not allowed:\n",
    "    st.error(\"System is configured to run predictions only between 18:00 and 22:00 (Asia/Kolkata). Please come back during that window.\")\n",
    "st.sidebar.header(\"Model\")\n",
    "if model is None or labels is None:\n",
    "    st.sidebar.warning(\"Model not found. Run capture_dataset.py to gather data, then train_model.py to create the model.\")\n",
    "else:\n",
    "    st.sidebar.success(f\"Loaded model with {len(labels)} classes\")\n",
    "\n",
    "tabs = st.tabs([\"Upload Image\", \"Realtime Webcam\"])\n",
    "with tabs[0]:\n",
    "    st.header(\"Upload an image (png/jpg)\")\n",
    "    uploaded = st.file_uploader(\"Upload hand image\", type=[\"png\", \"jpg\", \"jpeg\"])\n",
    "    if uploaded is not None:\n",
    "        file_bytes = np.asarray(bytearray(uploaded.read()), dtype=np.uint8)\n",
    "        img = cv2.imdecode(file_bytes, cv2.IMREAD_COLOR)\n",
    "        vec, lm = extract_landmarks_from_image(img)\n",
    "        display_img = img.copy()\n",
    "        if lm is not None:\n",
    "            mp_drawing.draw_landmarks(display_img, lm, mp_hands.HAND_CONNECTIONS)\n",
    "            st.image(cv2.cvtColor(display_img, cv2.COLOR_BGR2RGB), caption=\"Detected hand\")\n",
    "            if model is not None and allowed:\n",
    "                label, conf, proba = predict_from_vector(model, labels, vec)\n",
    "                st.success(f\"Prediction: **{label}** ({conf*100:.1f}% confidence)\")\n",
    "            elif not allowed:\n",
    "                st.warning(\"Prediction disabled — outside operational hours.\")\n",
    "            else:\n",
    "                st.warning(\"Model not available.\")\n",
    "        else:\n",
    "            st.warning(\"No hand detected in image. Try a clearer image or different pose.\")\n",
    "\n",
    "with tabs[1]:\n",
    "    st.header(\"Realtime webcam detection\")\n",
    "    st.write(\"Click 'Start' to open your webcam. Predictions will be shown on each frame.\")\n",
    "    start = st.button(\"Start Webcam\")\n",
    "    stop = st.button(\"Stop Webcam\")\n",
    "    run_live = False\n",
    "    if start:\n",
    "        run_live = True\n",
    "    if stop:\n",
    "        run_live = False\n",
    "    placeholder = st.empty()\n",
    "    if run_live:\n",
    "        cap = cv2.VideoCapture(0)\n",
    "        with mp_hands.Hands(static_image_mode=False, max_num_hands=1,\n",
    "                            min_detection_confidence=0.6, min_tracking_confidence=0.6) as hands:\n",
    "            while True:\n",
    "                ret, frame = cap.read()\n",
    "                if not ret:\n",
    "                    break\n",
    "                frame = cv2.flip(frame, 1)\n",
    "                rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                res = hands.process(rgb)\n",
    "                label_text = \"\"\n",
    "                if res.multi_hand_landmarks:\n",
    "                    lm = res.multi_hand_landmarks[0]\n",
    "                    mp_drawing.draw_landmarks(frame, lm, mp_hands.HAND_CONNECTIONS)\n",
    "                    vec = np.array([[p.x, p.y, p.z] for p in lm.landmark]).flatten()\n",
    "                    if model is not None and allowed:\n",
    "                        label, conf, _ = predict_from_vector(model, labels, vec)\n",
    "                        label_text = f\"{label} ({conf*100:.1f}%)\"\n",
    "                    elif not allowed:\n",
    "                        label_text = \"Outside allowed hours\"\n",
    "                cv2.putText(frame, label_text, (10,30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255,0), 2)\n",
    "                placeholder.image(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB), channels=\"RGB\")\n",
    "                if st.session_state.get(\"stop_signal\", False):\n",
    "                    break\n",
    "        cap.release()\n",
    "    else:\n",
    "        st.info(\"Press Start Webcam to begin.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
